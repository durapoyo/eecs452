import sys
import time
import cv2
import serial
import threading
import numpy as np
from pathlib import Path
from PyQt5 import QtWidgets, QtCore
import pyqtgraph as pg
from picamera2 import Picamera2
import mediapipe as mp

# ============================================================
# SERIAL SETUP
# ============================================================
try:
    teensy = serial.Serial('/dev/ttyACM0', 115200, timeout=0)
    print("Connected to Teensy")
except Exception as e:
    print("Serial Error:", e)
    teensy = None

last_sent_gesture = None

# ============================================================
# GUI CLASS
# ============================================================
class DJGui(QtWidgets.QWidget):

    def __init__(self):
        super().__init__()

        self.setWindowTitle("Teensy DJ Controller")
        layout = QtWidgets.QVBoxLayout(self)

        # -------------------
        # Waveform Panels
        # -------------------
        self.waveA = pg.PlotWidget(title="Deck A Waveform")
        self.waveB = pg.PlotWidget(title="Deck B Waveform")
        self.waveACurve = self.waveA.plot(pen='g')
        self.waveBCurve = self.waveB.plot(pen='c')

        layout.addWidget(self.waveA)
        layout.addWidget(self.waveB)

        # -------------------
        # Volume Meter
        # -------------------
        self.volumeBar = QtWidgets.QProgressBar()
        self.volumeBar.setRange(0, 100)
        self.volumeBar.setFormat("Volume: %p%")
        layout.addWidget(self.volumeBar)

        # -------------------
        # Crossfade Position
        # -------------------
        self.crossfadeSlider = QtWidgets.QSlider(QtCore.Qt.Horizontal)
        self.crossfadeSlider.setRange(0, 100)
        self.crossfadeSlider.setEnabled(False)
        layout.addWidget(self.crossfadeSlider)

        # -------------------
        # IMU Graphs
        # -------------------
        self.imuPlot = pg.PlotWidget(title="IMU Data (Accel Y & Gyro X)")
        self.accelCurve = self.imuPlot.plot(pen='y')
        self.gyroCurve = self.imuPlot.plot(pen='r')
        layout.addWidget(self.imuPlot)

        self.accelHistory = []
        self.gyroHistory = []

        # update timer
        self.timer = QtCore.QTimer()
        self.timer.timeout.connect(self.update_gui)
        self.timer.start(30)

    # ------------------------------------------------------------
    # GUI UPDATE
    # ------------------------------------------------------------
    def update_gui(self):
        """Update curves based on latest telemetry."""
        global latest_accel_y, latest_gyro_x
        global latest_crossfade, latest_volume

        # IMU plots
        self.accelHistory.append(latest_accel_y)
        self.gyroHistory.append(latest_gyro_x)

        if len(self.accelHistory) > 200:
            self.accelHistory = self.accelHistory[-200:]
            self.gyroHistory = self.gyroHistory[-200:]

        self.accelCurve.setData(self.accelHistory)
        self.gyroCurve.setData(self.gyroHistory)

        # Volume meter
        self.volumeBar.setValue(int(latest_volume * 100))

        # Crossfade slider
        self.crossfadeSlider.setValue(int(latest_crossfade * 100))

        # Dummy waveforms (replace with real audio FFT later)
        t = np.linspace(0, 1, 300)
        self.waveACurve.setData(np.sin(2*np.pi*3*t))
        self.waveBCurve.setData(np.sin(2*np.pi*5*t))


# ============================================================
# TELEMETRY PARSER THREAD
# ============================================================
latest_accel_y = 0
latest_gyro_x = 0
latest_volume = 0
latest_crossfade = 0

def serial_reader():
    global latest_accel_y, latest_gyro_x
    global latest_volume, latest_crossfade

    while True:
        if teensy and teensy.in_waiting:
            line = teensy.readline().decode(errors='ignore').strip()
            if line.startswith("IMU:"):
                parts = line.split(",")
                latest_accel_y = float(parts[2])
                latest_gyro_x = float(parts[4])
            elif line.startswith("AUDIO:"):
                parts = line.split(",")
                latest_volume = float(parts[1])
                latest_crossfade = float(parts[3])
        time.sleep(0.005)


# ============================================================
# MEDIAPIPE CALLBACK
# ============================================================
def send_gesture_to_teensy(code):
    global last_sent_gesture
    if teensy and code != last_sent_gesture:
        teensy.write(bytes([code]))
        last_sent_gesture = code
        print("Sent:", code)


def mp_callback(result, output_image, time_ms):
    if result and result.gestures:
        g = result.gestures[0][0].category_name
        if g == "Open_Palm": send_gesture_to_teensy(1)
        elif g == "Closed_Fist": send_gesture_to_teensy(2)
        elif g == "Pointing_Up": send_gesture_to_teensy(4)
        elif g == "Thumb_Up": send_gesture_to_teensy(5)
        elif g == "Thumb_Down": send_gesture_to_teensy(6)


# ============================================================
# MAIN
# ============================================================
def main():
    # Start serial thread
    threading.Thread(target=serial_reader, daemon=True).start()

    # Build GUI
    app = QtWidgets.QApplication(sys.argv)
    gui = DJGui()
    gui.show()

    # Start MediaPipe thread
    threading.Thread(target=run_mediapipe, daemon=True).start()

    sys.exit(app.exec_())


# ============================================================
# MEDIAPIPE LOOP
# ============================================================
def run_mediapipe():
    BaseOptions = mp.tasks.BaseOptions
    GestureRecognizer = mp.tasks.vision.GestureRecognizer
    GestureRecognizerOptions = mp.tasks.vision.GestureRecognizerOptions
    RunningMode = mp.tasks.vision.RunningMode
    Image = mp.Image

    opt = GestureRecognizerOptions(
        base_options=BaseOptions(model_asset_path="gesture_recognizer.task"),
        running_mode=RunningMode.LIVE_STREAM,
        result_callback=mp_callback
    )

    with GestureRecognizer.create_from_options(opt) as recognizer:
        picam2 = Picamera2()
        picam2.configure(picam2.create_preview_configuration(
            main={"format": "RGB888", "size": (320, 240)}))
        picam2.start()

        while True:
            frame = picam2.capture_array()
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            mp_image = Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)
            recognizer.recognize_async(mp_image, int(time.time()*1000))


# ============================================================
if __name__ == "__main__":
    main()
